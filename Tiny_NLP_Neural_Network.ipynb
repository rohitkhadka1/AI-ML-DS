{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53302925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import re \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe8e3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "        (\"What is the capital of Nepal?\", \"Kathmandu\"),\n",
    "        (\"What is the capital of India?\", \"New Delhi\"),\n",
    "    (\"What's the capital of France?\", \"Paris\"),\n",
    "    (\"Tell me the capital city of Japan.\", \"Tokyo\"),\n",
    "    (\"Which city is the capital of India?\", \"New Delhi\"),\n",
    "    (\"France's capital city is what?\", \"Paris\"),\n",
    "    (\"Name the capital of Japan.\", \"Tokyo\"),\n",
    "    (\"What is Japan's capital?\", \"Tokyo\"),\n",
    "    (\"Capital of India is?\", \"New Delhi\"),\n",
    "    (\"Can you tell me the capital of France?\", \"Paris\")\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "697c6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    return re.findall(r'\\b\\w+\\b', text.lower()) # removes punctuation and splits words \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd90c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Vocabulary \n",
    "word_freq = defaultdict(int)\n",
    "for sentence, _ in training_data:\n",
    "    for word in tokenize_text(sentence):\n",
    "        word_freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b573e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word-to-index mapping\n",
    "word_to_ix = {word: i for i, word in enumerate(word_freq)}\n",
    "word_to_ix[\"<UNK>\"] = len(word_to_ix) # Add unknown token\n",
    "ix_to_word = {i: word for word, i in word_to_ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e497edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output label mappings\n",
    "capital_to_ix = {\"New Delhi\": 0, \"Paris\": 1, \"Tokyo\": 2, \"Kathmandu\" : 3}\n",
    "ix_to_capital = {v: k for k, v in capital_to_ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a20988e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer function\n",
    "def tokenize(sentence):\n",
    "    tokens = tokenize_text(sentence)\n",
    "    return [word_to_ix.get(word, word_to_ix[\"<UNK>\"]) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d36d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model \n",
    "class CapitalQA(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeds = self.embedding(x)\n",
    "        pooled = embeds.mean(dim = 0)\n",
    "        out = self.fc(pooled)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42444876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup \n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "EMBED_DIM = 32 \n",
    "OUTPUT_DIM = len(capital_to_ix)\n",
    "\n",
    "model = CapitalQA(VOCAB_SIZE, EMBED_DIM, OUTPUT_DIM)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65e8a179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Loss: 14.8908\n",
      "Epoch 50 | Loss: 0.0632\n",
      "Epoch 100 | Loss: 0.0155\n",
      "Epoch 150 | Loss: 0.0067\n",
      "Epoch 200 | Loss: 0.0036\n",
      "Epoch 250 | Loss: 0.0022\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    for sentence, capital in training_data:\n",
    "        inputs = torch.tensor(tokenize(sentence))\n",
    "        target = torch.tensor([capital_to_ix[capital]])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(inputs)\n",
    "        loss = loss_fn(logits.unsqueeze(0), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch} | Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50f762c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    with torch.no_grad():\n",
    "        inputs = torch.tensor(tokenize(sentence))\n",
    "        logits = model(inputs)\n",
    "        pred_ix = torch.argmax(logits).item()\n",
    "        return ix_to_capital[pred_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e122552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Ask Your Questions!\n",
      "Q: What is the capital of India? â†’ A: New Delhi\n",
      "Q: What's the capital of France? â†’ A: Paris\n",
      "Q: Tell me the capital city of Japan. â†’ A: Tokyo\n",
      "Q: Can you tell me the capital of India? â†’ A: New Delhi\n",
      "Q: India capital? â†’ A: New Delhi\n",
      "Q: India capital â†’ A: New Delhi\n",
      "Q: France's capital city? â†’ A: Paris\n",
      "Q: What is the capital of Germany? â†’ A: Kathmandu\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ§  Ask Your Questions!\")\n",
    "test_sentences = [\n",
    "    \"What is the capital of India?\",\n",
    "    \"What's the capital of France?\",\n",
    "    \"Tell me the capital city of Japan.\",\n",
    "    \"Can you tell me the capital of India?\",\n",
    "    \"India capital?\",\n",
    "    \"India capital\",\n",
    "    \"France's capital city?\",\n",
    "    \"What is the capital of Germany?\"  # Unseen\n",
    "]\n",
    "\n",
    "for q in test_sentences:\n",
    "    print(f\"Q: {q} â†’ A: {predict(q)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55838581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Delhi'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Capital of Bhutan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b186643b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New Delhi'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Capital city of Bhutan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d782f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
